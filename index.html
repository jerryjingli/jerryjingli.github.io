<!DOCTYPE html>
<html>
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
<!--   <title>Li Jing - Nanyang Technological University (NTU)</title> -->

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=0.85">

 
  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="http://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">


 <!-- Scripts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src="js/jquery.min.js"></script>

  
  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

       
 <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">
  <link rel="stylesheet" type="text/css" href="css/custom.css"> 

        
       
    

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/favicon.png">

   

   

  <script src="js/site.js"></script>

<!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=eb3a&d=9gYcBi7vGfkRh_ZDs1qVy_FrbDiLr3V4NFRNgJpr6P4"></script> -->




<!-- back to top button jquery -->
<!--     <script src="http://code.jquery.com/jquery-1.11.3.min.js"></script>    -->


  <!-- create the back to top button -->
    <script type="text/javascript">

    var amountScrolled = 300;

    $(window).scroll(function() {
      if ( $(window).scrollTop() > amountScrolled ) {
        $('a.back-to-top').fadeIn('slow');
      } else {
        $('a.back-to-top').fadeOut('slow');
      }
    });

    $('a.back-to-top, a.simple-back-to-top').click(function() {
      $('html, body').animate({
        scrollTop: 0
      }, 50);
      return false;
    });
    </script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110819220-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-110819220-2');
</script>

</head>



<body style="background-image: url('images/bg.png');">
<!-- <body> -->
     <!-- back to top button start -->
        <a href="" class="back-to-top">Back to Top</a>
        <!-- back to top button end -->




 <div class="container">



    <div  class="navbar-spacer"></div>
        <div style="background-image: url('images/bg.png');" class="navbar" > 
        <div class="container">  
            <ul class="navbar-list">
          <li class="navbar-item-left"><a class="navbar-link-left">Jing Li (<font face="华文行楷">李晶</font>)</a></li>
                <li class="navbar-item"><a class="navbar-link" href="http://faculty.hitsz.edu.cn/lijing" target="_blank">中文</a></li>
                <li class="navbar-item"><a class="navbar-link" href="team.html">Team</a></li>
           <li class="navbar-item"><a class="navbar-link" href="fulllist.html">Publications</a></li>
                <li class="navbar-item"><a class="navbar-link active" href="index.html">Home</a></li>
             </ul>  
         </div>
         </div>










<div class="sidenav" style="font-size:90%;">

 <img align="middle"  class="headshot" id='JingLI80.jpg' src='images/JingLi19-1.PNG' width='100%'/>

<!-- <div class="member">
      <div class="image">
              <img align="middle"  class="headshot" id='JingLI80.jpg' src='images/JingLi19.PNG' width='100%'>
                  <div class="hover-image">
                  <img align="middle"  class="headshot" id='jingli-hover.jpg' src='images/jingli-hover.jpg' width='100%' >
                </div>
      </div>
  </div> -->


                    <p style="font-size:120%;"> <b>Dr. Jing Li</b></p>
                   <p> <b>Professor</b>, Harbin Institute of Technology (Shenzhen), China.</p>
                    <p><b>Email</b>: li.jing [AT] hit [DOT] edu [DOT] cn</p>

    <div align="center">  
      <a target="_blank" href="http://www.clustrmaps.com/map/li-jing.com" title="Visitor Map for li-jing.com"><img src="//www.clustrmaps.com/map_v2.png?u=eb3a&d=9gYcBi7vGfkRh_ZDs1qVy_FrbDiLr3V4NFRNgJpr6P4" style="display: none;"/></a>
  </div>
<br/>

</div>






<div class="mymain">


<div class="docs-section">
            <h5> <strong>About Me</strong></h5>
            <p >  

            <span style='color: red;'> <b>Prospective students:</b></span> 
I am always looking for strong and motivated <b>Postdoc/PhD/Master/RA</b> students to join my group. Please drop me an email with your CV if you are interested. <b><a style="color: red;" href="recruit.html" target="_blank"> 详见招生信息</a></b></br> </br>


Dr. Jing Li is currently a Professor at <a style="text-decoration:none;" href="http://en.hitsz.edu.cn/" target="_blank"> Harbin Institute of Technology (Shenzhen)</a> . 
Prior to that, he was a Research Scientist at the <a style="text-decoration:none;" href="http://www.inceptioniai.org/" target="_blank">Inception Institute of Artificial Intelligence (IIAI)</a>, Abu Dhabi, United Arab Emirates. He was a Research Fellow in the School of Computer Science and Engineering, <a style="text-decoration:none;" href="http://www.ntu.edu.sg" target="_blank">Nanyang Technological University (NTU)</a>, Singapore. 
He obtained his PhD degree in Computer Science, at NTU, Singapore in 2018. He received his B.E. and M.E. both from <a style="text-decoration:none;" href="http://www.uestc.edu.cn" target="_blank"> University of Electronic Science and Technology of China (UESTC)</a>, China.
His research aims to build up semantic Web systems to support information needs of web users via deep text understanding, information extraction,  machine intelligent question answering, knowledge representation, as well as social media analysis.
</p>


<!-- , under the supervision of Prof. <a style="text-decoration:none;" href="http://www.ntu.edu.sg/home/axsun/index.html" target="_blank">Aixin Sun</a> and  Prof. <a style="text-decoration:none;" href="https://cecs.anu.edu.au/people/zhenchang-xing" target="_blank">Zhenchang Xing</a> -->



<!--  <ul style="margin: 0rem 0 0rem 2rem;">
                                <li style="margin-bottom: 0rem;">2019.1 - Present, Research Scientist, <a style="text-decoration:none;" href="http://www.inceptioniai.org/" target="_blank">IIAI</a>, United Arab Emirates </li>
                                <li style="margin-bottom: 0rem;">2018.1 - 2018.12, Research Fellow, <a style="text-decoration:none;" href="http://www.ntu.edu.sg" target="_blank">NTU</a>, Singapore</li>
                                <li style="margin-bottom: 0rem;">2014.1 - 2018.1, Ph.D., <a style="text-decoration:none;" href="http://www.ntu.edu.sg" target="_blank">NTU</a>, Singapore</li>
                                <li style="margin-bottom: 0rem;">2010.9 - 2013.7, M.E., <a style="text-decoration:none;" href="http://www.uestc.edu.cn" target="_blank">UESTC</a>, China</li>
                                <li style="margin-bottom: 0rem;">2006.9 - 2010.7, B.E., <a style="text-decoration:none;" href="http://www.uestc.edu.cn" target="_blank">UESTC</a>, China </li>
</ul>       -->  


</div>




  
        <div class="docs-section">

<div class="row" style="padding:0; margin:0;">
            <div class="ten columns">  <!-- border-right -->
                      <h5><strong>Research Interests</strong></h5>

                         
                            <ul style="list-style-type:square; margin: 0rem 0 0rem 1rem;">        

                             <li style="margin-bottom: 0rem;">Natural Language Processing / Information Retrieval</li>
                                 <ul style="margin: 0rem 0 0rem 3rem;">
                                  <li style="margin-bottom: 0rem;">Large Langauge Models and Generative AI (PEFT, safety, etc.)</li>
                                  <li style="margin-bottom: 0rem;">Information Extraction and Knowledge Acquisition (NER, QA, etc.)</li>
                                <li style="margin-bottom: 0rem;">Knowledgeable NLP (Knowledge Graph, Reasoning, etc.)</li>
                                <li style="margin-bottom: 0rem;">Trustworthy NLP (Robust/adversarial, Low-resource, etc.)</li>
                                <li style="margin-bottom: 0rem;">AI for Software Engineering (Documentation Mining, Programming, etc.)</li>
                                </ul>        
                               
                                

                                <li style="margin-bottom: 0rem;">Machine Learning</li>
                                <ul style="margin: 0rem 0 0rem 3rem;">
                                <li style="margin-bottom: 0rem;">Transfer Learning</li> 
                                <li style="margin-bottom: 0rem;">Meta-learning</li>
                                <li style="margin-bottom: 0rem;">Adversarial Learning</li>
                                </ul>   
                                </ul>   

                            </ul>

            </div>


            <vr>
            <div class="five columns" style="padding:0.5rem; margin:0;">  <!-- style="padding:0; margin:0;" -->
        <!--     <h5> &nbsp; <strong>What's New <img src="images/new.jpg" width=40  align="bottom" ></strong></h5> -->


        </div>         
           
            

          
   </div>  

</div> <!-- <div class="docs-section"> -->














<div class="docs-section">


<!-- <confol style="counter-reset: my-c-counter 9;">
<ol style="counter-reset: my-j-counter 20;">
<li>Coffee</li>
<li>Tea</li>
<confli>Coffee</confli>
<li>Milk</li>
<confli>Coffee</confli>
<confli>Coffee</confli>
</ol>
</confol>
 -->


      <h5><strong>Selected Publications [<a style="text-decoration:none;" href="fulllist.html" target="_blank">Full List</a>] 

      [<a style="text-decoration:none;" href="https://scholar.google.com.sg/citations?hl=en&user=2QxEwWsAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Google Scholar</a>] </strong></h5> 
    


<div id="book"> 
  <span class="sb"><b>Books</b></span> 
  <div class="wrapper"><a href="https://item.jd.com/71105463307.html" target="_blank"><img src="images/KG2020.png" width=150px align="left" /></a>
  <span >
    &nbsp &nbsp Authors: Xiaoyan Zhu, <strong>Jing Li</strong>, Yu Hao, Han Xiao and Minlie Huang<br>
    &nbsp &nbsp Publisher: Publishing House of Electronics Industry <br>
    &nbsp &nbsp ISBN: 9787121389924 <br>
    &nbsp &nbsp Publish time: June 1st, 2020<br>
       &nbsp &nbsp Links: <a style="text-decoration:none;" href="https://item.jd.com/71105463307.html" target="_blank">JD.com</a>, <a style="text-decoration:none;" href="https://detail.tmall.com/item.htm?spm=a220m.1000858.1000725.76.719d27f1R22o7D&id=621549168024&skuId=4611686639976555928&areaId=511300&user_id=1932014659&cat_id=2&is_b=1&rn=f1816d379fa2edae9d0fa7d81f34b98f" target="_blank">Tmall.com</a><br>
    <br>
    <br>
    <br>
      </span></div>
</div>







<jol style="counter-reset: my-j-counter 10;">
      <confol style="counter-reset: my-c-counter 5;">
  






<!-- <p style="margin: 0rem 0 1rem -3rem;"><strong>Submitted</strong></p>  --> <!-- style="margin: 0rem 0 1rem -4rem;" -->



<!-- <h3 class="yearsubmitted">Submitted</h3> -->
<!-- <li > <strong>Named Entity Boundary Detection via Meta-Learning</strong><br/>
       <i> <strong>Jing Li</strong><br/>
<strong>Under review</strong>
</i> </li>


<li > <strong>Few-Shot Named Entity Recognition</strong><br/>
       <i> <strong>Jing Li</strong><br/>
<strong>Under review</strong>
</i> </li>
 -->




<li > <strong>A Survey on Deep Learning for Named Entity Recognition</strong><br/>
      <i> <strong>Jing Li</strong>, Aixin Sun, Jianglei Han and Chenliang Li<br/>
      <span class="abbpaper">IEEE TKDE-22</span>- IEEE Transactions on Knowledge and Data Engineering, 34(1): 50-70, 2022.  <br/>

      <a class="file_link" href="papers/22nersurvey.pdf" target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_survey20').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_survey20').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a>
      <br/>

      <div id="abstract_survey20" class="verbatim" style="display:none">
    Named entity recognition (NER) is the task to identify text spans that mention named entities, and to classify them into predefined categories such as person, location, organization etc. NER serves as the basis for a variety of natural language applications such as question answering, text summarization, and machine translation. Although early NER systems are successful in producing decent recognition accuracy, they often require much human effort in carefully designing rules or features. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding state-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.
      </div>

      <div id="bibtex_survey20" style="display:none">
      <pre class="verbatim">
@article{jing22nersurvey,
author    = {Jing Li and Aixin Sun and Jianglei Han and Chenliang Li},
title     = {A Survey on Deep Learning for Named Entity Recognition},
journal   = {IEEE Transactions on Knowledge and Data Engineering (TKDE)},
volume    = {34},
number    = {1},
pages     = {50--70},
year      = {2022},
url       = {https://doi.org/10.1109/TKDE.2020.2981314},
doi       = {10.1109/TKDE.2020.2981314},
}
      </pre>
      </div>

</i> </li>



<confli > <strong>Rethinking Document-Level Relation Extraction: A Reality Check </strong><br/>
      <i> <strong>Jing Li</strong>, Yequan Wang, Shuai Zhang and Min Zhang<br/>
      <span class="abbpaper">ACL-23</span>- Findings of The 61st Annual Meeting of the Association for Computational Linguistics, 2023. <br/>

      <a class="file_link" href="https://arxiv.org/pdf/2306.08953.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_acl23').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_acl23').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> 


      <br/>

      <div id="abstract_acl23" class="verbatim" style="display:none">
Recently, numerous efforts have continued to push up performance boundaries of document-level relation extraction (DocRE) and have claimed significant progress in DocRE. In this paper, we do not aim at proposing a novel model for DocRE. Instead, we take a closer look at the field to see if these performance gains are actually true. By taking a comprehensive literature review and a thorough examination of popular DocRE datasets, we find that these performance gains are achieved upon a strong or even untenable assumption in common: all named entities are perfectly localized, normalized, and typed in advance. Next, we construct four types of entity mention attacks to examine the robustness of typical DocRE models by behavioral probing. We also have a close check on model usability in a more realistic setting. Our findings reveal that most of current DocRE models are vulnerable to entity mention attacks and difficult to be deployed in real-world end-user NLP applications. Our study calls more attentions for future research to stop simplifying problem setups, and to model DocRE in the wild rather than in an unrealistic Utopian world.
   </div>

      <div id="bibtex_acl23" style="display:none">
        <pre class="verbatim">
@inproceedings{li2023rethinking,
  title={Rethinking Document-Level Relation Extraction: A Reality Check},
  author={Li, Jing and Wang, Yequan and Zhang, Shuai and Zhang, Min},
  pages= {5715--5730},
  booktitle = {Findings of The 61st Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2023}
}
      </pre>
      </div>

</i> </confli>





<li > <strong>Few-Shot Relation Extraction With Dual Graph Neural Network Interaction</strong><br/>
      <i> <strong>Jing Li</strong>, Shanshan Feng and Billy Chiu<br/>
      <span class="abbpaper">IEEE TNNLS-23</span>-  IEEE Transactions on Neural Networks and Learning Systems, 2023.  <br/>

      <a class="file_link" href="papers/23tnnlsdualgraph.pdf" target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_tnnls23').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_tnnls23').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a>
      <br/>

      <div id="abstract_tnnls23" class="verbatim" style="display:none">
 Recent advances in relation extraction with deep neural architectures have achieved excellent performance. However, current models still suffer from two main drawbacks: 1) they require enormous volumes of training data to avoid model overfitting and 2) there is a sharp decrease in performance when the data distribution during training and testing shift from one domain to the other. It is thus vital to reduce the data requirement in training and explicitly model the distribution difference when transferring knowledge from one domain to another. In this work, we concentrate on few-shot relation extraction under domain adaptation settings. Specifically, we propose, a novel graph neural network (GNN) based approach for few-shot relation extraction. leverages an edge-labeling dual graph (i.e. an instance graph and a distribution graph) to explicitly model the intraclass similarity and interclass dissimilarity in each individual graph, as well as the instance-level and distribution-level relations across graphs. A dual graph interaction mechanism is proposed to adequately fuse the information between the two graphs in a cyclic flow manner. We extensively evaluate on FewRel1.0 and FewRel2.0 benchmarks under four few-shot configurations. The experimental results demonstrate that can match or outperform previously published approaches. We also perform experiments to further investigate the parameter settings and architectural choices, and we offer a qualitative analysis.
      </div>

      <div id="bibtex_tnnls23" style="display:none">
      <pre class="verbatim">
@article{jing23dualgraph,
  title={Few-Shot Relation Extraction With Dual Graph Neural Network Interaction},
  author={Li, Jing and Feng, Shanshan and Chiu, Billy},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  pages={Early Access},
  year={2023},
  publisher={IEEE}
}
      </pre>
      </div>

</i> </li>




<li > <strong>Sequence Labeling with Meta-Learning</strong><br/>
      <i> <strong>Jing Li</strong>, Peng Han, Xiangnan Ren, Jilin Hu, Lisi Chen and Shuo Shang<br/>
      <span class="abbpaper">IEEE TKDE-23</span>- IEEE Transactions on Knowledge and Data Engineering, 35(3): 3072-3086, 2023. <br/>

      <a class="file_link" href="papers/21metaseq.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_seq21').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_seq21').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a>
      <br/>

      <div id="abstract_seq21" class="verbatim" style="display:none">
Recent neural architectures in sequence labeling have yielded state-of-the-art performance on single domain data such as newswires. However, they still suffer from (i) requiring massive amounts of training data to avoid overfitting; (ii) huge performance degradation when there is a domain shift in the data distribution between training and testing. In this paper, we investigate the problem of domain adaptation for sequence labeling under homogeneous and heterogeneous settings. We propose MetaSeq, a novel meta-learning approach for domain adaptation in sequence labeling. Specifically, MetaSeq incorporates meta-learning and adversarial training strategies to encourage robust, general and transferable representations for sequence labeling. The key advantage of MetaSeq is that it is capable of adapting to new unseen domains with a small amount of annotated data from those domains. We extensively evaluate MetaSeq on named entity recognition, part-of-speech tagging and slot filling tasks under homogeneous and heterogeneous settings. The experimental results show that MetaSeq achieves state-of-the-art performance against eight baselines. Impressively, MetaSeq surpasses the in-domain performance using only 16.17% and 7% of target domain data on average for homogeneous settings, and 34.76%, 24%, 22.5% of target domain data on average for heterogeneous settings.
      </div>

      <div id="bibtex_seq21" style="display:none">
      <pre class="verbatim">
@article{jing23seq,
author    = {Jing Li and Peng Han and Xiangnan Ren and Jilin Hu and Lisi Chen and Shuo Shang},
title     = {Sequence Labeling with Meta-Learning},
journal   = {IEEE Transactions on Knowledge and Data Engineering (TKDE)},
volume       = {35},
number       = {3},
pages        = {3072--3086},
year         = {2023},
url       = {https://doi.org/10.1109/TKDE.2021.3118469},
doi       = {10.1109/TKDE.2021.3118469},
}
      </pre>
      </div>

</i> </li>








<li > <strong>Neural Text Segmentation and Its Application to Sentiment Analysis</strong><br/>
      <i> <strong>Jing Li</strong>, Billy Chiu, Shuo Shang and Ling Shao<br/>
      <span class="abbpaper">IEEE TKDE-22</span>- IEEE Transactions on Knowledge and Data Engineering, 34(2): 828-842, 2022.  <br/>

      <a class="file_link" href="papers/21Segsentiment.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_sentiment20').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_sentiment20').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> &nbsp 

      <a class="file_link" href="http://138.197.118.157:8000/segbot/"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> Demo</a>  


      <br/>

      <div id="abstract_sentiment20" class="verbatim" style="display:none">
Text segmentation is a fundamental task in natural language processing. Depending on the levels of granularity, the task can be defined as segmenting a document into topical segments, or segmenting a sentence into elementary discourse units (EDUs). Traditional solutions to the two tasks heavily rely on carefully designed features. The recently proposed neural models do not need manual feature engineering, but they either suffer from sparse boundary tags or cannot efficiently handle the issue of variable size output vocabulary. In light of such limitations, we propose a generic end-to-end segmentation model, namely SEGBOT, which first uses a bidirectional recurrent neural network to encode an input text sequence. SEGBOT then uses another recurrent neural networks, together with a pointer network, to select text boundaries in the input sequence. In this way, SEGBOT does not require any hand-crafted features. More importantly, SEGBOT inherently handles the issue of variable size output vocabulary and the issue of sparse boundary tags. In our experiments, SEGBOT outperforms state-of-the-art models on two tasks: document-level topic segmentation and sentence-level EDU segmentation. As a downstream application, we further propose a hierarchical attention model for sentence-level sentiment analysis based on the outcomes of SEGBOT. The hierarchical model can make full use of both word-level and EDU-level information simultaneously for sentence-level sentiment analysis. In particular, it can effectively exploit EDU-level information, such as the inner properties of EDUs, which cannot be fully encoded in word-level features. Experimental results show that our hierarchical model achieves new state-of-the-art results on the Movie Review and Stanford Sentiment Treebank benchmarks.
   </div>

      <div id="bibtex_sentiment20" style="display:none">
      <pre class="verbatim">
@article{li22segsenti,
author    = {Jing Li and Billy Chiu and Shuo Shang and Ling Shao},
title     = {Neural Text Segmentation and Its Application to Sentiment Analysis},
journal   = {IEEE Transactions on Knowledge and Data Engineering (TKDE)},
volume    = {34},
number    = {2},
pages     = {828--842},
year      = {2022},
url       = {https://doi.org/10.1109/TKDE.2020.2983360},
doi       = {10.1109/TKDE.2020.2983360},
}
      </pre>
      </div>

</i> </li>







<li > <strong>Few-Shot Named Entity Recognition via Meta-Learning</strong><br/>
      <i> <strong>Jing Li</strong>, Billy Chiu, Shanshan Feng and Hao Wang<br/>
      <span class="abbpaper">IEEE TKDE-22</span>- IEEE Transactions on Knowledge and Data Engineering, 34(9): 4245-4256, 2022. <br/>

      <a class="file_link" href="papers/20TKDEfewshot.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_fewshot20').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_fewshot20').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a>
      <br/>

      <div id="abstract_fewshot20" class="verbatim" style="display:none">
Few-shot learning under the N-way K-shot setting (i.e., K annotated samples for each of N classes) has been widely studied in relation extraction (e.g., FewRel) and image classification (e.g., Mini-ImageNet). Named entity recognition (NER) is typically framed as a sequence labeling problem where the entity classes are inherently entangled together because the entity number and classes in a sentence are not known in advance, leaving the N-way K-shot NER problem so far unexplored. In this paper, we first formally define a more suitable N-way K-shot setting for NER. Then we propose FewNER, a novel meta-learning approach for few-shot NER. FewNER separates the entire network into a task-independent part and a task-specific part. During training in FewNER, the task-independent part is meta-learned across multiple tasks and a task-specific part is learned for each single task in a low-dimensional space. At test time, FewNER keeps the task-independent part fixed and adapts to a new task via gradient descent by updating only the task-specific part, resulting in it being less prone to overfitting and more computationally efficient. The results demonstrate that FewNER achieves state-of-the-art performance against nine baseline methods by significant margins on three adaptation experiments.
   </div>

      <div id="bibtex_fewshot20" style="display:none">
      <pre class="verbatim">
@article{li20fewshot,
author    = {Jing Li and Billy Chiu and Shanshan Feng and Hao Wang},
title     = {Few-Shot Named Entity Recognition via Meta-Learning},
journal   = {IEEE Transactions on Knowledge and Data Engineering (TKDE)},
volume       = {34},
number       = {9},
pages        = {4245--4256},
year         = {2022},
url       = {https://doi.org/10.1109/TKDE.2020.3038670},
doi       = {10.1109/TKDE.2020.3038670},
}
      </pre>
      </div>

</i> </li>





<li > <strong>Neural Named Entity Boundary Detection</strong><br/>
      <i> <strong>Jing Li</strong>, Aixin Sun and Yukun Ma<br/>
      <span class="abbpaper">IEEE TKDE-22</span>- IEEE Transactions on Knowledge and Data Engineering, 33(4): 1790-1795, 2021. <br/>

      <a class="file_link" href="papers/21boundary.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_bdrybot20').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_bdrybot20').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> &nbsp 

      <a class="file_link" href="http://138.197.118.157:8000/bdrybot/"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> Demo</a>  


      <br/>

      <div id="abstract_bdrybot20" class="verbatim" style="display:none">
In this paper, we focus on named entity boundary detection , which is to detect the start and end boundaries of an entity mention in text, without predicting its type. The detected entities are input to entity linking or fine-grained typing systems for semantic enrichment. We propose BdryBot , a recurrent neural network encoder-decoder framework with a pointer network to detect entity boundaries from a given sentence. The encoder considers both character-level representations and word-level embeddings to represent the input words. In this way, BdryBot does not require any hand-crafted features. Because of the pointer network, BdryBot overcomes the problem of variable size output vocabulary and the issue of sparse boundary tags. We conduct two sets of experiments, in-domain detection and cross-domain detection, on six datasets. Our results show that BdryBot achieves state-of-the-art performance against five baselines. In addition, our proposed approach can be further enhanced when incorporating contextualized language embeddings into token representations.
   </div>

      <div id="bibtex_bdrybot20" style="display:none">
      <pre class="verbatim">
@article{li21bdrybot,
author    = {Jing Li and Aixin Sun and Yukun Ma},
title     = {Neural Named Entity Boundary Detection},
journal   = {IEEE Transactions on Knowledge and Data Engineering (TKDE)},
volume    = {33},
number    = {4},
pages     = {1790--1795},
year      = {2021},
url       = {https://doi.org/10.1109/TKDE.2020.2981329},
doi       = {10.1109/TKDE.2020.2981329},
}
      </pre>
      </div>

</i> </li>














<li > <strong>Domain Generalization for Named Entity Boundary Detection via Meta-Learning</strong><br/>
      <i> <strong>Jing Li</strong>, Shuo Shang and Lisi Chen<br/>
      <span class="abbpaper">IEEE TNNLS-21</span>- IEEE Transactions on Neural Networks and Learning Systems, 32(9): 3819-3830, 2021. <br/>

      <a class="file_link" href="papers/21tnnls.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_domainG20').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_domainG20').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> 


      <br/>

      <div id="abstract_domainG20" class="verbatim" style="display:none">
Named entity recognition (NER) aims to recognize mentions of rigid designators from text belonging to predefined semantic types, such as person, location, and organization. In this article, we focus on a fundamental subtask of NER, named entity boundary detection, which aims at detecting the start and end boundaries of an entity mention in the text, without predicting its semantic type. The entity boundary detection is essentially a sequence labeling problem. Existing sequence labeling methods either suffer from sparse boundary tags (i.e., entities are rare and nonentities are common) or they cannot well handle the issue of variable size output vocabulary (i.e., need to retrain models with respect to different vocabularies). To address these two issues, we propose a novel entity boundary labeling model that leverages pointer networks to effectively infer boundaries depending on the input sequence. On the other hand, training models on source domains that generalize to new target domains at the test time are a challenging problem because of the performance degradation. To alleviate this issue, we propose METABDRY, a novel domain generalization approach for entity boundary detection without requiring any access to target domain information. Especially, adversarial learning is adopted to encourage domain-invariant representations. Meanwhile, metalearning is used to explicitly simulate a domain shift during training so that metaknowledge from multiple resource domains can be effectively aggregated. As such, METABDRY explicitly optimizes the capability of ``learning to generalize,'' resulting in a more general and robust model to reduce the domain discrepancy. We first conduct experiments to demonstrate the effectiveness of our novel boundary labeling model. We then extensively evaluate METABDRY on eight data sets under domain generalization settings. The experimental results show that METABDRY achieves state-of-the-art results against the recent seven baselines.
   </div>

      <div id="bibtex_domainG20" style="display:none">
      <pre class="verbatim">
@article{li21domaingen,
author    = {Jing Li and Shuo Shang and Lisi Chen},
title     = {Domain Generalization for Named Entity Boundary Detection via Metalearning},
journal   = {IEEE Transactions on Neural Networks and Learning Systems (TNNLS)},
volume    = {32},
number    = {9},
pages     = {3819--3830},
year      = {2021},
url       = {https://doi.org/10.1109/TNNLS.2020.3015912},
doi       = {10.1109/TNNLS.2020.3015912},
}
      </pre>
      </div>

</i> </li>










  


<li  > <strong>Leveraging Official Content and Social Context to Recommend Software Documentation</strong><br/>
      <i> <strong>Jing Li</strong>, Zhenchang Xing  and Muhammad Ashad Kabir<br/>
      <span class="abbpaper">IEEE TSC-21</span>- IEEE Transactions on Services Computing, 14(2), 472-486, 2021. <br/>

      <a class="file_link" href="papers/21TSC.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_tsc18').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_tsc18').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> 


      <br/>

      <div id="abstract_tsc18" class="verbatim" style="display:none">
For an unfamiliar Application Programming Interface (API), software developers often access the official documentation to learn its usage, and post questions related to this API on social question and answering (Q&A) sites to seek solutions. The official software documentation often captures the information about functionality and parameters, but lacks detailed descriptions in different usage scenarios. On the contrary, the discussions about APIs on social Q&A sites provide enriching usages. Moreover, existing code search engines and information retrieval systems cannot effectively return relevant software documentation when the issued query does not contain code snippets or API-like terms. In this paper, we present CnCxL2R , a software documentation recommendation strategy incorporating the content of official documentation and the social context on Q&A into a learning-to-rank schema. In the proposed strategy, the content, local context and global context of documentation are considered to select candidate documents. Then four types of features are extracted to learn a ranking model. We conduct a large-scale automatic evaluation on Java documentation recommendation. The results show that CnCxL2R achieves state-of-the-art performance over the eight baseline models. We also compare the CnCxL2R with Google search. The results show that CnCxL2R can recommend more relevant software documentation, and can effectively capture the semantic between the high-level intent in developers’ queries and the low-level implementation in software documentation.
     </div>

      <div id="bibtex_tsc18" style="display:none">
      <pre class="verbatim">
@article{TSCLiXK21,
  author    = {Jing Li and
               Zhenchang Xing and
               Muhammad Ashad Kabir},
  title     = {Leveraging Official Content and Social Context to Recommend Software
               Documentation},
  journal   = {{IEEE} Trans. Serv. Comput.},
  volume    = {14},
  number    = {2},
  pages     = {472--486},
  year      = {2021},
  url       = {https://doi.org/10.1109/TSC.2018.2812729},
  doi       = {10.1109/TSC.2018.2812729},
}
      </pre>
      </div>

</i> </li>

  









<confli > <strong>MetaNER: Named Entity Recognition with Meta-Learning </strong><br/>
      <i> <strong>Jing Li</strong>, Shuo Shang and Ling Shao<br/>
      <span class="abbpaper">WWW-20</span>- The Web Conference, 2020. Acceptance rate: 217/1129 (19.2%). <br/>

      <a class="file_link" href="papers/20MetaNER.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_metaner').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_metaner').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> 


      <br/>

      <div id="abstract_metaner" class="verbatim" style="display:none">
Recent neural architectures in named entity recognition (NER) have yielded state-of-the-art performance on single domain data such as newswires. However, they still suffer from (i) requiring massive amounts of training data to avoid overfitting; (ii) huge performance degradation when there is a domain shift in the data distribution between training and testing. In this paper, we investigate the problem of domain adaptation for NER under homogeneous and heterogeneous settings. We propose MetaNER, a novel meta-learning approach for domain adaptation in NER. Specifically, MetaNER incorporates meta-learning and adversarial training strategies to encourage robust, general and transferable representations for sequence labeling. The key advantage of MetaNER is that it is capable of adapting to new unseen domains with a small amount of annotated data from those domains. We extensively evaluate MetaNER on multiple datasets under homogeneous and heterogeneous settings. The experimental results show that MetaNER achieves state-of-the-art performance against eight baselines. Impressively, MetaNER surpasses the in-domain performance using only 16.17% and 34.76% of target domain data on average for homogeneous and heterogeneous settings, respectively.
   </div>

      <div id="bibtex_metaner" style="display:none">
      <pre class="verbatim">
@inproceedings{li20metaner,
author    = {Jing Li and Shuo Shang and Ling Shao},
title     = {MetaNER: Named Entity Recognition with Meta-Learning},
booktitle = {The Web Conference 2020 (WWW)},
pages     = {429--440},
year      = {2020},
url       = {https://doi.org/10.1145/3366423.3380127},
}
      </pre>
      </div>

</i> </confli>





      





<!-- <p style="margin: 0rem 0 1rem -3rem;"><strong>Published</strong></p> -->




<confli > <strong>Adversarial Transfer for Named Entity Boundary Detection with Pointer Networks</strong><br/>
      <i> <strong>Jing Li</strong>, Deheng Ye and Shuo Shang<br/>
      <span class="abbpaper">IJCAI-19</span>- The 28th International Joint Conference on Artificial Intelligence, Pages 5053-5069, 2019. Acceptance rate: 850/4752 (17.9%). <br/>

      <a class="file_link" href="https://www.ijcai.org/proceedings/2019/0702.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_adt19').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_adt19').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> 


      <br/>

      <div id="abstract_adt19" class="verbatim" style="display:none">
In this paper, we focus on named entity boundary detection, which aims to detect the start and end boundaries of an entity mention in text, without predicting its type. A more accurate and robust detection approach is desired to alleviate error propagation in downstream applications, such as entity linking and fine-grained typing systems. Here, we first develop a novel entity boundary labeling approach with pointer networks, where the output dictionary size depends on the input, which is variable. Furthermore, we propose AT-Bdry, which incorporates adversarial transfer learning into an end-to-end sequence labeling model to encourage domain-invariant representations. More importantly, AT-Bdry can reduce domain difference in data distributions between the source and target domains, via an unsupervised transfer learning approach (i.e., no annotated target-domain data is necessary). We conduct Formal Text to Formal Text, Formal Text to Informal Text and ablation evaluations on five benchmark datasets. Experimental results show that AT-Bdry achieves state-of-the-art transferring performance against recent baselines. 
   </div>

      <div id="bibtex_adt19" style="display:none">
      <pre class="verbatim">
@inproceedings{li19advt,
author    = {Jing Li and Deheng Ye andd Shuo Shang},
title     = {Adversarial Transfer for Named Entity Boundary Detection with Pointer Networks},
booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI)},
pages     = {5053--5059},
year      = {2019},
url       = {https://doi.org/10.24963/ijcai.2019/702},
}
      </pre>
      </div>

</i> </confli>






<confli  > <strong>SegBot: A Generic Neural Text Segmentation Model with Pointer Network</strong><br/>
      <i> <strong>Jing Li</strong>, Aixin Sun and Shafiq Joty<br/>
      <span class="abbpaper">IJCAI-18</span>-The 27th International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence. Pages 4166-4172, 2018. Acceptance rate: 710/3470 (20.5%).  <br/>

      <a class="file_link" href="https://www.ijcai.org/proceedings/2018/0579.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_segbot').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_segbot').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a>  &nbsp 

       <a class="file_link" href="http://138.197.118.157:8000/segbot/"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> Demo</a>  


      <br/>

      <div id="abstract_segbot" class="verbatim" style="display:none">
Text segmentation is a fundamental task in natural language processing that comes in two levels of granularity: (i) segmenting a document into a sequence of topical segments (topic segmentation), and (ii) segmenting a sentence into a sequence of elementary discourse units (EDU segmentation). Traditional solutions to the two tasks heavily rely on carefully designed features. The recently proposed neural models do not need manual feature engineering, but they either suffer from sparse boundary tags or they cannot well handle the issue of variable size output vocabulary. We propose a generic end-to-end segmentation model called SegBot. SegBot uses a bidirectional recurrent neural network to encode input text sequence. The model then uses another recurrent neural network together with a pointer network to select text boundaries in the input sequence. In this way, SegBot does not require hand-crafted features. More importantly, our model inherently handles the issue of variable size output vocabulary and the issue of sparse boundary tags. In our experiments, SegBot outperforms state-of-the-art models on both topic and EDU segmentation tasks.
   </div>

      <div id="bibtex_segbot" style="display:none">
      <pre class="verbatim">
@inproceedings{LiSJ18segbot,
  author    = {Jing Li and Aixin Sun and Shafiq R. Joty},
  title     = {SegBot: {A} Generic Neural Text Segmentation Model with Pointer Network},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI)},
  pages     = {4166--4172},
  year      = {2018},
  url       = {https://doi.org/10.24963/ijcai.2018/579},
  doi       = {10.24963/ijcai.2018/579},
}
      </pre>
      </div>

</i> </confli>





      

<li > <strong>Learning to Answer Programming Questions with Software Documentation through Social Context Embedding</strong><br/>
      <i> <strong>Jing Li</strong>, Aixin Sun and Zhenchang Xing<br/>
      <span class="abbpaper">INS-18</span>- Information Sciences. Volumes 448–449, Pages 36-52,  June 2018, Elsevier. <br/>

      <a class="file_link" href="papers/18LearingtoAnswer.pdf"  target="_blank" style="text-decoration:none;"> <i class="fa fa-file-pdf-o"></i> PDF</a>  &nbsp 


      <a class="file_link" data-toggle="dropdown" href="javascript:void(0);" style="text-decoration:none;" onclick="$('#abstract_l2a18').slideToggle('fast');return false;">
                             <i class="fa fa-file-text-o"></i> Abstract</a> &nbsp 

      <a class="file_link" data-toggle="dropdown" style="text-decoration:none;" href="javascript:void(0);" onclick="$('#bibtex_l2a18').slideToggle('fast');return false;"> <i class="fa fa-book"></i> BibTex</a> 


      <br/>

      <div id="abstract_l2a18" class="verbatim" style="display:none">
Official software documentation provides a comprehensive overview of software usages, but not on specific programming tasks or use cases. Often there is a mismatch between the documentation and a question on a specific programming task because of different wordings. We observe from Stack Overflow that the best answers to programmers’ questions often contain links to formal documentation. In this paper, we propose a novel deep-learning-to-answer framework, named QDLinker, for answering programming questions with software documentation. QDLinker learns from the large volume of discussions in community-based question answering site to bridge the semantic gap between programmers’ questions and software documentation. Specifically, QDLinker learns question-documentation semantic representation from these question answering discussions with a four-layer neural network, and incorporates semantic and content features into a learning-to-rank schema. Our approach does not require manual feature engineering or external resources to infer the degree of relevance between a question and documentation. Through extensive experiments, results show that QDLinker effectively answers programming questions with direct links to software documentation. QDLinker significantly outperforms the baselines based on traditional retrieval models and Web search services dedicated for software documentation retrieval. The user study shows that QDLinker effectively bridges the semantic gap between the intent of a programming question and the content of software documentation.
     </div>

      <div id="bibtex_l2a18" style="display:none">
      <pre class="verbatim">
@article{L2ALiSX18,
  author    = {Jing Li and
               Aixin Sun and
               Zhenchang Xing},
  title     = {Learning to answer programming questions with software documentation
               through social context embedding},
  journal   = {Information Sciences},
  volume    = {448-449},
  pages     = {36--52},
  year      = {2018},
  url       = {https://doi.org/10.1016/j.ins.2018.03.014},
  doi       = {10.1016/j.ins.2018.03.014},
}
      </pre>
      </div>

</i> </li>


  





      


        
       
 

<!-- </i></confli>
 -->


<!-- <strong>Before PhD </strong> -->

<!-- <h4 class="year">Before 2015</h4>

<br>
   <li  ><strong> Applications of Compressed Sensing for Multiple Transmitters Multiple Azimuth Beams SAR Imaging </strong><br/>
<i> <strong>Jing Li</strong>, Shunsheng Zhang,Junfei Chang <br/>
 <span class="abbpaper">PIER-12</span>-  Progress In Electromagnetics Research, Vol. 127, Pages 259–275, 2012. (<strong><span class="pierif"></span></strong>)
<a class="file_link"  href="papers/Applications of Compressed Sensing for Multiple Transmitters Multiple Azimuth Beams SAR Imaging.pdf" target="_blank">PDF </a></i></li>
     

   <li  ><strong> Forward-Looking Bistatic SAR Imaging Based On High Order Range Equation And High Order Phase Compensation  </strong><br/>
<i> Shunsheng Zhang and <strong>Jing Li*</strong><br/>
<span class="abbpaper">JEWA-12</span>- Journal of Electromagnetic Waves and Applications, vol.26, nos.17-18, pages 2304-2314, 2012. (<strong><span class="jewaif"></span></strong>)
<a class="file_link" href="papers/Forward-Looking BistaticSAR Imaging Based On High Order Range Equation And High Order Phase Compensation.pdf" target="_blank">PDF</a> *Corresponding author</i></li> 

 -->



            </confli>

      </jli>
    </div>









<!-- Journal Edition Associate Editor:Co-Guest Editor
Conference Organization Committee
Conference Area Chairs
Conference Senior PC Members
Workshop Organization
Conference PC Members
Journal Reviewers -->


<!-- <div class="docs-section">
      <h5><strong>Professional Services</strong></h5>
<ul style="list-style-type:square; margin: 0rem 0 0rem 1rem;">  


                             <li style="margin-bottom: 0rem;">Conference PC Members </li>
                                 <ul style="margin: 0rem 0 0rem 3rem;">
                                  <li style="margin-bottom: 0rem;">The International Joint Conference on Artificial Intelligence (IJCAI 2020) </li>
                                <li style="margin-bottom: 0rem;">The ACM International Conference on Information and Knowledge Management (CIKM 2019) </li>
                                <li style="margin-bottom: 0rem;">The Asia Information Retrieval Societies Conference (AIRS 2019)</li>
                                </ul>    


                                 <li style="margin-bottom: 0rem;">Journal Reviewers</li>
                                 <ul style="margin: 0rem 0 0rem 3rem;">
                                 <li style="margin-bottom: 0rem;">IEEE Journal on Selected Areas in Communications (JSAC) </li>
                                <li style="margin-bottom: 0rem;">IEEE Transactions on Knowledge and Data Engineering (TKDE) </li>
                                <li style="margin-bottom: 0rem;">Elsevier, Neurocomputing</li>
                                <li style="margin-bottom: 0rem;">Wiley, Journal of the Association for Information Science and Technology (JASIST)</li>
                                <li style="margin-bottom: 0rem;">Springer, Knowledge and Information Systems (KAIS)</li>
                                <li style="margin-bottom: 0rem;">IEEE Access</li>
                                </ul>    
                          
</ul>
</br>
</div>
 -->







</div>
<footer id="credits" >   
        <p align="center"><span class="nobreak">Copyright &copy; 2015 - 2024 Jing LI </p> 
          <!-- &nbsp;<i class="fa fa-envelope fa-1x"/></i> lijing@li-jing.com</span> -->
    </footer>




 
 

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  </div>






</div>

</body>
</html>

